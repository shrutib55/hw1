# -*- coding: utf-8 -*-
"""hw1_pt1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19JT_yD4cT8NjT9uovlKk8wLcDKUIx0li
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

yr18 = pd.read_csv('/content/2018.csv')
yr19 = pd.read_csv('/content/2019.csv')
hap = pd.concat([yr18, yr19],ignore_index=True)

hap = hap.drop(['Overall rank', 'Country or region'],axis=1)

#hap['Perceptions of corruption'] = hap['Perceptions of corruption'].map(lambda a: np.exp(a))

train= hap.sample(frac=0.8,random_state=200)
test= hap.drop(train.index)

sns.pairplot(data = hap)

x = train.drop(['Score'],axis=1)
y = train['Score']

testx = test.drop(['Score'],axis=1)
testy = test['Score']

# the gradient for my situation
def ssr_gradient(x, y, w):
    res = w[0] + w[1] * x.iloc[:,0] + w[2] * x.iloc[:,1] + w[3] * x.iloc[:,2] + w[4] * x.iloc[:,3] + w[5] * x.iloc[:,4] + w[6] * x.iloc[:,5] - y
    sse = sum(pow(res,2))
    mse.append(sse/len(x))
    return res.mean(), (res * x.iloc[:,0]).mean(), (res*x.iloc[:,1]).mean(), (res*x.iloc[:,2]).mean(), (res*x.iloc[:,3]).mean(), (res*x.iloc[:,4]).mean(), (res*x.iloc[:,5]).mean() # .mean() is a method of np.ndarray

# generic method to minimize ANY convex function in the world
def gradient_descent(
     gradient, x, y, start, learn_rate=0.1, n_iter=50, tolerance=1e-06
 ):
  vector = start
  for _ in range(n_iter):
    diff = -learn_rate * np.array(gradient(x, y, vector))
    if np.all(np.abs(diff) <= tolerance):
      break
    vector += diff
  return vector

mse = []
w = gradient_descent(
    ssr_gradient, x, y, start=[0,0,0,0,0,0,0], learn_rate=0.00016,
    n_iter= 10000
)
w

xs = [x for x in range(len(mse))]

plt.plot(xs, mse)
plt.show()



sse = sum(pow(w[0] + w[1] * x.iloc[:,0] + w[2] * x.iloc[:,1] + w[3] * x.iloc[:,2] + w[4] * x.iloc[:,3] + w[5] * x.iloc[:,4] + w[6] * x.iloc[:,5] - y, 2))

tss = sum(pow(y.mean() - y, 2))

r2 = 1- (sse/tss)
r2

n = len(x)

mse2 = sse/n
mse2

sse = sum(pow(w[0] + w[1] * testx.iloc[:,0] + w[2] * testx.iloc[:,1] + w[3] * testx.iloc[:,2] + w[4] * testx.iloc[:,3] + w[5] * testx.iloc[:,4] + w[6] * testx.iloc[:,5] - testy, 2))

tss = sum(pow(y.mean() - testy, 2))

r2 = 1- (sse/tss)
r2

n = len(testx)

mse2 = sse/n
mse2
